{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data - Tri-Cities, Washington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> This purpose of this project is to take a certain area of land and wrangle the data. Extract and clean the data to make it much more uniform and readable. The area I have chosen is an area called 'Tri-Cities' in Washington State. I chose this area as I have lived here for a long time. The original OpenStreetMap data I am using for this project can be found and exported [Here](https://www.openstreetmap.org/export#map=11/46.2421/-119.1886). I used an API called Overpass API to export this data. The documentation for Overpass API can be found [Here](https://wiki.openstreetmap.org/wiki/Overpass_API). The finished project and all files will be uploaded to [This GitHub Repository](https://github.com/TrikerDev/Wrangle-OpenStreetMap-Data---Tri-Cities---Washington)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing OSM File and packages\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import pandas\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import sqlite3\n",
    "import cerberus\n",
    "import schema\n",
    "import os\n",
    "\n",
    "\n",
    "OSM_FILE = \"map.osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting tags\n",
    "def get_element(filename, tags=('node', 'way', 'relation')):\n",
    "    context = iter(ET.iterparse(filename, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 15770,\n",
      " 'meta': 1,\n",
      " 'nd': 434301,\n",
      " 'node': 368263,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 1431,\n",
      " 'tag': 158810,\n",
      " 'way': 38417}\n"
     ]
    }
   ],
   "source": [
    "# Counting and returning tag counts per type of tag\n",
    "def count_tags(filename):\n",
    "    tree=ET.iterparse(filename)\n",
    "    tags={}\n",
    "    for event,elem in tree:\n",
    "        if elem.tag not in tags.keys():\n",
    "            tags[elem.tag]=1\n",
    "        else:\n",
    "            tags[elem.tag] = tags[elem.tag]+1\n",
    "    return tags    \n",
    "    \n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    tags=count_tags(OSM_FILE)\n",
    "    pprint.pprint(tags)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the 'K' value of each tag and adding to a dictionary\n",
    "\n",
    ">*  \"lower\", for tags that contain only lowercase letters and are valid\n",
    ">*  \"lower_colon\", for otherwise valid tags with a colon in their names\n",
    ">*  \"problemchars\", for tags with problematic characters\n",
    ">*  \"other\", for other tags that do not fall into the other three categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 111439, 'lower_colon': 43264, 'other': 4106, 'problemchars': 1}\n"
     ]
    }
   ],
   "source": [
    "# Adding variables for the tags to be stored under, definitions above\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "    \n",
    "# Function starting on our dataset\n",
    "def process_keys_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "# Iterating through tags and adding them up\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] = keys['problemchars'] + 1\n",
    "        else:    \n",
    "            keys['other'] += 1  \n",
    "    return keys\n",
    "\n",
    "\n",
    "# Opening file and starting process_keys_map function\n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    keys = process_keys_map(OSM_FILE)\n",
    "    pprint.pprint(keys)\n",
    "\n",
    "# Closing file\n",
    "f.close()\n",
    "\n",
    "# Below is the count of each type of variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting number of unique users that contributed to the map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n"
     ]
    }
   ],
   "source": [
    "# Function to count users\n",
    "def count_users(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.get('user'):\n",
    "            users.add(get_user(element))\n",
    "        element.clear()    \n",
    "    return users\n",
    "\n",
    "# Fetching users function\n",
    "def get_user(element):\n",
    "    return element.get('user')\n",
    "\n",
    "# Opening file and starting count_users function\n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    users = count_users(OSM_FILE)\n",
    "\n",
    "print (len(users))\n",
    "\n",
    "f.close()\n",
    "\n",
    "# user count below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['25or6to4',\n",
      "     '503Greg',\n",
      "     'AE35',\n",
      "     'Aaron Lidman',\n",
      "     'AaronAsAChimp',\n",
      "     'Acefirst',\n",
      "     'Adam Brault',\n",
      "     'Adam Schneider',\n",
      "     'Adamant1',\n",
      "     'Akgeo',\n",
      "     'Aleksandar Matejevic',\n",
      "     'Alex-a',\n",
      "     'AmandaCora',\n",
      "     'Amnesiac9',\n",
      "     'Amoebabadass',\n",
      "     'AndjelaS',\n",
      "     'Andre Engels',\n",
      "     'Andre68',\n",
      "     'AndrewSnow',\n",
      "     'AntonioPigafetta',\n",
      "     'ArizonaMapper',\n",
      "     'ArminGh',\n",
      "     'Audiophase',\n",
      "     'AzrielB',\n",
      "     'Azuka',\n",
      "     'BCNorwich',\n",
      "     'BadRegEx',\n",
      "     'Baloo Uriza',\n",
      "     'BaseballNut51',\n",
      "     'Belobog',\n",
      "     'Benny Goodman',\n",
      "     'Black Cardinal',\n",
      "     'Brad Meteor',\n",
      "     'Brian Bradford',\n",
      "     'Brian Reavis',\n",
      "     'Brian@Brea',\n",
      "     'Bryce C Nesbitt',\n",
      "     'CarniLvr79',\n",
      "     'Carnildo',\n",
      "     'Chenshi',\n",
      "     'Chetan_Gowda',\n",
      "     'ChrisZontine',\n",
      "     'Christopher-0118',\n",
      "     'Chroma187',\n",
      "     'Claudius Henrichs',\n",
      "     'DJ Cane',\n",
      "     'DKDestroyer',\n",
      "     'Daniel C Berman',\n",
      "     'DannyAiquipa',\n",
      "     'DanteVento',\n",
      "     'DareDJ',\n",
      "     'Darrell',\n",
      "     'DaveHansenTiger',\n",
      "     'Die immer lacht',\n",
      "     'Dieter Schmeer',\n",
      "     'Dilys',\n",
      "     'Dima Ser',\n",
      "     'Dion Dock',\n",
      "     'Dr Kludge',\n",
      "     'E-Layne',\n",
      "     'ELadner',\n",
      "     'Ed DeVoe',\n",
      "     'EdSS',\n",
      "     'Edward',\n",
      "     'EmlynSquare',\n",
      "     'EvanWeiner',\n",
      "     'Extramiler',\n",
      "     'Fogey7',\n",
      "     'Frankonaut',\n",
      "     'FritzyTG',\n",
      "     'FvGordon',\n",
      "     'GISCrow',\n",
      "     'GISgoddess',\n",
      "     'Gattacus',\n",
      "     'Geogast',\n",
      "     'Glassman',\n",
      "     'GoWestTravel',\n",
      "     'Greg_Rose',\n",
      "     'GuestOSM',\n",
      "     'Guylamar2006',\n",
      "     'H@mlet',\n",
      "     'Helmchen42',\n",
      "     'HendricksR',\n",
      "     'Heptazane',\n",
      "     'HermistonMap',\n",
      "     'HeyItsAdam',\n",
      "     'HolgerJeromin',\n",
      "     'HoloDuke',\n",
      "     'Howpper',\n",
      "     'HubMiner',\n",
      "     'Ice Harbor Lock and Dam',\n",
      "     'Imp_GL',\n",
      "     'Iowa Kid',\n",
      "     'JEStout',\n",
      "     'Jack McElroy',\n",
      "     'Jason Ferrier (Trailhead Labs)',\n",
      "     'Jesse Baker',\n",
      "     'Jessica12345',\n",
      "     'Jothirnadh',\n",
      "     'Jozzy',\n",
      "     'JpRimbauer',\n",
      "     'JulienBalas',\n",
      "     'Justho',\n",
      "     u'J\\xf3n',\n",
      "     'KanaLee',\n",
      "     'Karcaw',\n",
      "     'Kingdom2917',\n",
      "     'KitSEA',\n",
      "     'Kla_Ger',\n",
      "     'Klaus Schwer',\n",
      "     'Kozuch',\n",
      "     'KristenK',\n",
      "     'Kseniya_Nekrasava',\n",
      "     'LHuisingh',\n",
      "     'LLAQWA',\n",
      "     'LXT',\n",
      "     'LakatosVL',\n",
      "     'Ldore',\n",
      "     'LeeSea',\n",
      "     'Little Brother',\n",
      "     'LocalTrailgeek',\n",
      "     'LucasLarson',\n",
      "     'Luis36995',\n",
      "     'MajaMaravic',\n",
      "     'MandiLeigh',\n",
      "     'Manu1400',\n",
      "     'MappingJunkie',\n",
      "     'Marius Van Nieuwenhuyse',\n",
      "     'Marshall Carter',\n",
      "     'MasiMaster',\n",
      "     'Mason Bailie',\n",
      "     'Mateusz Konieczny - bot account',\n",
      "     'Math1985',\n",
      "     'McSoupie',\n",
      "     'Michael Bonebrake',\n",
      "     'MikeN',\n",
      "     'Milo',\n",
      "     'MirouStar',\n",
      "     'Misa_zumba',\n",
      "     'Mitch Myers',\n",
      "     'MojaveNC',\n",
      "     'NE2',\n",
      "     'Natfoot',\n",
      "     'NaviMen',\n",
      "     'NickBolten',\n",
      "     'OSMF Redaction Account',\n",
      "     'Olyon',\n",
      "     'Omnific',\n",
      "     'OpenTopoMap',\n",
      "     'OrcaDan',\n",
      "     'Oregonian3',\n",
      "     'Oroso',\n",
      "     'P38',\n",
      "     'PA94',\n",
      "     'PBX Tech',\n",
      "     'PHerison',\n",
      "     'Paradox460',\n",
      "     'ParagonPrime',\n",
      "     'Paul Buxton',\n",
      "     'Phil Scherer',\n",
      "     'PlaneMad',\n",
      "     'Polyglot',\n",
      "     'PulisakZ',\n",
      "     'RLugo',\n",
      "     'Radio1313',\n",
      "     'RetiredInNH',\n",
      "     'RichRico',\n",
      "     'Richard',\n",
      "     'Rick Rupp',\n",
      "     'RoadGeek_MD99',\n",
      "     'Ross Ellis',\n",
      "     'Rub21',\n",
      "     'Russ',\n",
      "     'Ryzen',\n",
      "     'SRHarrison',\n",
      "     'STA',\n",
      "     'Sheltiego',\n",
      "     'Shmias',\n",
      "     'Skybunny',\n",
      "     'Snowblind50999',\n",
      "     'SomeoneElse',\n",
      "     'Something B',\n",
      "     'Spanholz',\n",
      "     'StanB',\n",
      "     'StellanL',\n",
      "     'Stephen214',\n",
      "     'Stutech',\n",
      "     'Stutech6',\n",
      "     'Sundance',\n",
      "     'Sunny',\n",
      "     'SuperFlomm',\n",
      "     'Suthern',\n",
      "     'TIGERcnl',\n",
      "     'Takogin',\n",
      "     'Tamires24',\n",
      "     'Tecsomane',\n",
      "     'Thalmus084',\n",
      "     'TheDutchMan13',\n",
      "     'Timothy Smith',\n",
      "     'Timothy Whidden',\n",
      "     'ToeBee',\n",
      "     'TomInOz',\n",
      "     'TorCguy',\n",
      "     'TorhamZed',\n",
      "     'US Woods',\n",
      "     'USA Editor',\n",
      "     'Utible',\n",
      "     'VLD158',\n",
      "     'Var-vara',\n",
      "     'Velox',\n",
      "     'Wa17ru',\n",
      "     'Wadis',\n",
      "     'WanMil',\n",
      "     'Wim L',\n",
      "     'Wolfram Sobotta',\n",
      "     'X99',\n",
      "     'Zartbitter',\n",
      "     'Zineer',\n",
      "     'abel801',\n",
      "     'aceman444',\n",
      "     'adamos',\n",
      "     'adjuva',\n",
      "     'alexsoldatkin96',\n",
      "     'alexswann',\n",
      "     'alixhartmann',\n",
      "     'amillar',\n",
      "     'amm',\n",
      "     'andrewpmk',\n",
      "     'andygol',\n",
      "     'annakulikowa',\n",
      "     'atomwaffen',\n",
      "     'b-jazz',\n",
      "     'b-jazz-bot',\n",
      "     'bab72',\n",
      "     'balrog-kun',\n",
      "     'bbmiller',\n",
      "     'beweta',\n",
      "     'bhavana naga',\n",
      "     'bobolopolis',\n",
      "     'bogdanp_telenav',\n",
      "     'boopington',\n",
      "     'bot-mode',\n",
      "     'calfarome',\n",
      "     'caseyb',\n",
      "     'caspermonte',\n",
      "     'choess',\n",
      "     'clay_c',\n",
      "     'colindt',\n",
      "     'compdude',\n",
      "     'cowdog',\n",
      "     'crossdiver',\n",
      "     'daderkina',\n",
      "     'davidearl',\n",
      "     'dchiles',\n",
      "     'dcp',\n",
      "     'dekatherm',\n",
      "     'derFred',\n",
      "     'deserttrail',\n",
      "     'dirtyidol',\n",
      "     'dmgroom_ct',\n",
      "     'don-vip',\n",
      "     'eMerzh',\n",
      "     'ediyes',\n",
      "     'egore911',\n",
      "     'elbatrop',\n",
      "     'elkueb',\n",
      "     'emem',\n",
      "     'eric22',\n",
      "     'ethylisocyanat',\n",
      "     'eulochon',\n",
      "     'ewedistrict',\n",
      "     'ewetfly',\n",
      "     'eyewitness',\n",
      "     'fireferg',\n",
      "     'forkandwait',\n",
      "     'freebeer',\n",
      "     'fx99',\n",
      "     'gabis_telenav',\n",
      "     'geochrome',\n",
      "     'geoengineer44',\n",
      "     'glenn218k',\n",
      "     'gormur',\n",
      "     'gotterbild',\n",
      "     'govancanucks',\n",
      "     'gpserror',\n",
      "     'grantg',\n",
      "     'green525',\n",
      "     'gustafson',\n",
      "     'h4ck3rm1k3',\n",
      "     'haysdb',\n",
      "     'hazelwillow',\n",
      "     'henjf',\n",
      "     'herriotto',\n",
      "     'hobbesvsboyle',\n",
      "     'hofoen',\n",
      "     'homer__simpsons',\n",
      "     'houston_mapper1',\n",
      "     'iandees',\n",
      "     'ignignokt',\n",
      "     'interdite',\n",
      "     'jScher',\n",
      "     'jacobgonzalez',\n",
      "     'jaecord',\n",
      "     'jeff_meyers',\n",
      "     'jfire',\n",
      "     'jharpster',\n",
      "     'jinalfoflia',\n",
      "     'jneptune',\n",
      "     'joeymcgraw',\n",
      "     'jogger333',\n",
      "     'jojokant',\n",
      "     'jonesydesign',\n",
      "     'jose_sousa',\n",
      "     'jsaraceno',\n",
      "     'jsneider23',\n",
      "     'jtvandyk',\n",
      "     'jumbanho',\n",
      "     'kararcha',\n",
      "     'karitotp',\n",
      "     'karl-marx',\n",
      "     'kfremd',\n",
      "     'kh72022',\n",
      "     'kkoganti',\n",
      "     'klusark',\n",
      "     'korsvik',\n",
      "     'kwametedros',\n",
      "     'larz86',\n",
      "     'laylow506',\n",
      "     'ldermer',\n",
      "     'lemba',\n",
      "     'leuty',\n",
      "     'lialia_amber',\n",
      "     'mac99201',\n",
      "     'magrej',\n",
      "     'malcolmh',\n",
      "     'maning',\n",
      "     'map93',\n",
      "     'mapman44',\n",
      "     'mapper999',\n",
      "     'marianp_telenav',\n",
      "     'markm851003',\n",
      "     'marthaleena',\n",
      "     'matthews028',\n",
      "     'maxerickson',\n",
      "     'melcomsx',\n",
      "     'melisramer',\n",
      "     'methowmade',\n",
      "     'miroslavuzice87',\n",
      "     'mjdmorgan',\n",
      "     'mrlanduse',\n",
      "     'mstingm',\n",
      "     'mtmail',\n",
      "     'mueschel',\n",
      "     'muziriana',\n",
      "     'mvexel',\n",
      "     'n76',\n",
      "     'n7xsd',\n",
      "     'n_LH',\n",
      "     'nammala',\n",
      "     'nasirifard',\n",
      "     'nathan206',\n",
      "     'navosm',\n",
      "     'neuhausr',\n",
      "     'nextSibling',\n",
      "     'nikh1ll',\n",
      "     'nmixter',\n",
      "     'noliver',\n",
      "     'oanac2_telenav',\n",
      "     'okilimu',\n",
      "     'oldtopos',\n",
      "     'oliver01',\n",
      "     'oliviap_telenav',\n",
      "     'oormilavinod',\n",
      "     'pasukanoren',\n",
      "     'paulmach',\n",
      "     'pete404',\n",
      "     'petr_balicek',\n",
      "     'physisneakers',\n",
      "     'piligab',\n",
      "     'pkoby',\n",
      "     'plubs',\n",
      "     'pluton_od',\n",
      "     'pnorman',\n",
      "     'poornibadrinath',\n",
      "     'pratikyadav',\n",
      "     'pwhite119',\n",
      "     'pzzvz',\n",
      "     'r2_d1000',\n",
      "     'rambudo',\n",
      "     'ramyaragupathy',\n",
      "     'rapush',\n",
      "     'rbenite4',\n",
      "     'rgvaliant',\n",
      "     'ridixcr',\n",
      "     'rittoch',\n",
      "     'rkachelriess',\n",
      "     'ruraltom',\n",
      "     'ruthmaben',\n",
      "     'rza31',\n",
      "     'salix01',\n",
      "     'samely',\n",
      "     'scai',\n",
      "     'sctrojan79',\n",
      "     'sebastic',\n",
      "     'setheryb13',\n",
      "     'shawat94',\n",
      "     'shutle64',\n",
      "     'siayu',\n",
      "     'simonap_telenav',\n",
      "     'skoocoom',\n",
      "     'skquinn',\n",
      "     'snickerdoodles',\n",
      "     'spjaquish',\n",
      "     'srividya_c',\n",
      "     'steverumizen',\n",
      "     'stucki1',\n",
      "     'swimdb',\n",
      "     'tebiggs',\n",
      "     'teodorab_telenav',\n",
      "     'the Sandinator',\n",
      "     'theScutineer',\n",
      "     'thetornado76',\n",
      "     'tmay',\n",
      "     'todrobbins',\n",
      "     'tomthepom',\n",
      "     'tpearson',\n",
      "     'tumido',\n",
      "     'tyrosxps',\n",
      "     'tythegeek',\n",
      "     'uboot',\n",
      "     'user_5359',\n",
      "     'van Rees',\n",
      "     'vardhamk',\n",
      "     'vmonisha',\n",
      "     'voithos',\n",
      "     'vozsed',\n",
      "     'wambacher',\n",
      "     'wasat',\n",
      "     'wegavision',\n",
      "     'wilmaed',\n",
      "     'wilsamson12',\n",
      "     'wislander',\n",
      "     'woodpeck_fixbot',\n",
      "     'woodpeck_repair',\n",
      "     'wutzke',\n",
      "     'xogalla',\n",
      "     'xujiayi_1256',\n",
      "     'xybot',\n",
      "     'yasse1406',\n",
      "     'yurasi',\n",
      "     'zaizone',\n",
      "     'zehpunktbarron',\n",
      "     'zephyr'])\n"
     ]
    }
   ],
   "source": [
    "# Printing all unique usernames\n",
    "pprint.pprint(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Street Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:street\n",
      "['West 27th Avenue',\n",
      " 'Hunt Avenue',\n",
      " 'Fowler Street',\n",
      " 'Clearwater Avenue',\n",
      " 'Tapteal Drive',\n",
      " 'Willamette Ave',\n",
      " 'Queensgate Drive',\n",
      " 'Lee Boulevard',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Lee Boulevard',\n",
      " 'Williams Boulevard',\n",
      " 'Williams Boulevard',\n",
      " 'Queensgate Drive',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Lindberg Loop',\n",
      " 'Serivce Road',\n",
      " 'Bronco Lane',\n",
      " 'Bronco Lane',\n",
      " 'Bronco Lane',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Airport Way',\n",
      " 'Airport Way',\n",
      " 'Aviator Drive',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Terminal Drive',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Airport Way',\n",
      " 'Airport Way',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Butler Loop',\n",
      " 'Lindberg Loop',\n",
      " 'Terminal Drive',\n",
      " 'Terminal Drive',\n",
      " 'Terminal Drive',\n",
      " 'Terminal Drive',\n",
      " 'Terminal Drive',\n",
      " 'Terminal Drive',\n",
      " 'Terminal Drive',\n",
      " 'Bronco Lane',\n",
      " 'Terminal Drive',\n",
      " 'Terminal Drive',\n",
      " 'Williams Boulevard',\n",
      " 'So. Kent St.',\n",
      " 'West Court Street',\n",
      " 'West Court Street',\n",
      " 'Jadwin Avenue',\n",
      " 'George Washington Way',\n",
      " 'Wellsian Way',\n",
      " 'Sylvester Street',\n",
      " 'Sylvester Street',\n",
      " 'North Nevada Street',\n",
      " 'Stevens Drive',\n",
      " 'Travis Ct',\n",
      " 'Travis Court',\n",
      " 'Travis Ct',\n",
      " 'Travis Court',\n",
      " 'Travis Court',\n",
      " 'Travis Court',\n",
      " 'Stonecreek Drive',\n",
      " 'Williams Boulevard',\n",
      " 'George Washington Way',\n",
      " 'E. SR 397',\n",
      " 'Monument Drive',\n",
      " 'West Quinault Street',\n",
      " 'Columbia Center Boulevard',\n",
      " 'West Van Giesen Street',\n",
      " 'Duportail Street',\n",
      " 'Paradise Way',\n",
      " 'Paradise Way',\n",
      " 'Paradise Way',\n",
      " 'North Road 44',\n",
      " 'South 6th Avenue',\n",
      " 'Leslie Road',\n",
      " 'Swift Boulevard',\n",
      " 'McKay Road',\n",
      " 'South Washington St',\n",
      " 'South Washington Street',\n",
      " 'West 1st Avenue',\n",
      " 'Lincoln Landing',\n",
      " 'West Marie Street',\n",
      " 'North Ely Street',\n",
      " 'Sawgrass Loop',\n",
      " 'West Gage Boulevard',\n",
      " '20th Avenue',\n",
      " '20th Avenue',\n",
      " 'North Road 92',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'West Court Street',\n",
      " 'Court Street',\n",
      " '4th Avenue',\n",
      " 'Rickenbacker Drive',\n",
      " 'Rickenbacker Drive',\n",
      " 'Rickenbacker Drive',\n",
      " 'Rickenbacker Drive',\n",
      " 'West Court Street',\n",
      " 'West Court Street',\n",
      " 'West Court Street',\n",
      " 'Duportail Street',\n",
      " 'Queensgate Drive',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Duportail Street',\n",
      " 'Queensgate Drive',\n",
      " 'Queensgate Drive',\n",
      " 'North 10th Avenue',\n",
      " 'West Lewis Street',\n",
      " 'West Clearwater Avenue',\n",
      " 'George Washington Way',\n",
      " 'George Washington Way',\n",
      " 'George Washington Way',\n",
      " 'North Kellogg Street',\n",
      " 'Dale Avenue',\n",
      " 'South Union Place',\n",
      " 'South Union Place',\n",
      " 'George Washington Way',\n",
      " 'Butler Loop',\n",
      " 'South Washington Street',\n",
      " 'North 1st Avenue',\n",
      " 'North 1st Avenue',\n",
      " 'Duval Loop',\n",
      " 'West Gage Boulevard',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'George Washington Way',\n",
      " 'Duportail Street',\n",
      " 'Duportail Street',\n",
      " 'Queensgate Drive',\n",
      " 'Queensgate Drive',\n",
      " 'Bombing Range Road',\n",
      " '20th Avenue',\n",
      " '9th Street',\n",
      " 'Bombing Range Road',\n",
      " 'Gage Boulevard',\n",
      " 'West Clearwater Avenue',\n",
      " 'Gage Boulevard',\n",
      " 'Columbia Center Boulevard',\n",
      " 'George Washington Way',\n",
      " 'South Union Street',\n",
      " 'North Columbia Center Boulevard',\n",
      " 'Duportail Street',\n",
      " 'West Okanogan Avenue',\n",
      " 'Burden Boulevard',\n",
      " 'North Road 68',\n",
      " 'Duportail Street',\n",
      " 'Bombing Range Road',\n",
      " 'N Irving Pl',\n",
      " 'Columbia Center Boulevard',\n",
      " 'Amon Park Road',\n",
      " 'Lee Boulevard',\n",
      " 'South Auburn Street',\n",
      " 'South Auburn Street',\n",
      " 'West 10th Avenue',\n",
      " 'West 10th Place',\n",
      " 'South Quillan Street',\n",
      " 'George Washington Way',\n",
      " 'West Kennewick Ave',\n",
      " 'West Kennewick Ave',\n",
      " 'Monument Drive',\n",
      " 'Duportail Street',\n",
      " 'North 4th Avenue',\n",
      " 'North 4th Avenue',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'West Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'North 20th Avenue',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'West Court Street',\n",
      " 'North 4th Avenue',\n",
      " 'North 1st Avenue',\n",
      " 'North 20th Avenue',\n",
      " 'West Sylvester Street',\n",
      " 'North Road 68',\n",
      " 'West Hopkins Street',\n",
      " 'North 4th Avenue',\n",
      " 'Lee Boulevard',\n",
      " 'Lee Boulevard',\n",
      " 'Lee Boulevard',\n",
      " 'North 3rd Avenue',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " '4th Avenue',\n",
      " '4th Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Williams Boulevard',\n",
      " 'Lee Boulevard',\n",
      " 'Jadwin Avenue',\n",
      " 'Lee Boulevard',\n",
      " 'Williams Boulevard',\n",
      " 'Torbett Street',\n",
      " 'Jadwin Avenue',\n",
      " 'Knight Street',\n",
      " 'Jadwin Avenue',\n",
      " 'Northgate Drive',\n",
      " 'Jadwin Avenue',\n",
      " 'Lee Boulevard',\n",
      " 'George Washington Way',\n",
      " 'George Washington Way',\n",
      " 'Cullum Avenue',\n",
      " 'N Columbia Center Boulevard',\n",
      " 'North 20th Avenue',\n",
      " 'Terminal Drive',\n",
      " 'North Auburn Street',\n",
      " 'Shockley Road',\n",
      " 'Tamarisk Dr',\n",
      " 'Tamarisk Dr',\n",
      " 'Indian Ridge Dr',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Serena Lane',\n",
      " 'Serena Lane',\n",
      " 'Serena Lane',\n",
      " 'Cathedral Drive',\n",
      " 'Cathedral Drive',\n",
      " 'Cathedral Drive',\n",
      " 'Angelo Lane',\n",
      " 'Cathedral Drive',\n",
      " 'Hovley Lane',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Indian Ridge Drive',\n",
      " 'Serena Lane',\n",
      " 'Tamarisk Drive',\n",
      " 'Angelo Lane',\n",
      " 'Hovley Lane',\n",
      " 'Hovley Lane',\n",
      " 'Ava Way',\n",
      " 'Corvina Street',\n",
      " 'Meritage Avenue',\n",
      " 'Highview Street',\n",
      " 'Malbec Avenue',\n",
      " 'Bellaview Avenue',\n",
      " 'Dupont Avenue',\n",
      " 'Barbera Street',\n",
      " 'Daphne Avenue',\n",
      " 'Parkview Avenue',\n",
      " 'Camillia Avenue',\n",
      " 'Syrah Avenue',\n",
      " 'Tawny Avenue',\n",
      " 'Cullum Avenue',\n",
      " 'Bradley Boulevard',\n",
      " 'West Argent Road',\n",
      " '20th Avenue',\n",
      " '20th Avenue',\n",
      " 'Bombing Range Road',\n",
      " 'N Columbia Center Boulevard',\n",
      " 'South Union Street',\n",
      " 'West Gage Boulevard',\n",
      " 'Paradise Way',\n",
      " 'Diamond Head Way',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'West Van Giesen Street',\n",
      " 'Rickenbacker Drive',\n",
      " 'Rickenbacker Drive',\n",
      " 'Plaza Way',\n",
      " 'Plaza Way',\n",
      " 'Bombing Range Road',\n",
      " 'Waikiki Court',\n",
      " 'Diamond Head Way',\n",
      " 'Columbia Point Drive',\n",
      " 'Columbia Point Drive',\n",
      " 'Columbia Point Drive',\n",
      " 'Swift Boulevard',\n",
      " 'West Canal Drive',\n",
      " 'Country Haven Loop',\n",
      " 'Thayer Drive',\n",
      " 'Road 36',\n",
      " 'Road 36',\n",
      " 'Road 36',\n",
      " 'Mahan Avenue',\n",
      " 'Duportail Street',\n",
      " 'West Duportail Street',\n",
      " 'Queensgate Drive',\n",
      " 'Queensgate Drive',\n",
      " 'Queensgate Drive',\n",
      " 'Broadmoor Boulevard',\n",
      " 'Chapel Hill Boulevard',\n",
      " 'Broadmoor Boulevard',\n",
      " 'McKay Road',\n",
      " 'Trippe Street',\n",
      " 'Trippe Street',\n",
      " 'Trippe Street',\n",
      " 'Trippe Street',\n",
      " 'Torbett Street',\n",
      " 'Torbett Street',\n",
      " 'Torbett Street',\n",
      " 'Torbett Street',\n",
      " 'Ridgeline Drive',\n",
      " 'Keene Road',\n",
      " 'Polar Way',\n",
      " 'Columbia Center Boulevard',\n",
      " 'Columbia Center Boulevard',\n",
      " 'South Clodfelter Road',\n",
      " 'Muriel Street',\n",
      " 'Cottonwood Creek Blvd',\n",
      " 'Cottonwood Creek Blvd',\n",
      " 'E Foster Wells Road',\n",
      " 'Broadmoor Boulevard',\n",
      " 'Malbec Avenue',\n",
      " 'Ava Way',\n",
      " 'North Neel Street',\n",
      " 'West Lewis Street',\n",
      " '20th Avenue',\n",
      " '20th Avenue',\n",
      " 'West Lewis Street',\n",
      " '20th Avenue',\n",
      " '20th Avenue',\n",
      " 'North 20th Avenue',\n",
      " '20th Avenue',\n",
      " 'West Shoshone Street',\n",
      " 'West Shoshone Street',\n",
      " 'West Shoshone Street',\n",
      " 'West Shoshone Street',\n",
      " 'West Shoshone Street',\n",
      " '20th Avenue',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Cartmell Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'Court Street',\n",
      " 'North 22nd Avenue',\n",
      " 'Court Street',\n",
      " 'West 10th Avenue',\n",
      " 'Court Street',\n",
      " 'South 18th Avenue',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Hibiscus Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Forsythia Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Daisy Street',\n",
      " 'Keene Road',\n",
      " 'Duportail Street',\n",
      " 'Horne Drive',\n",
      " 'South Dayton Street',\n",
      " 'Court Street',\n",
      " 'Columbia Center Boulevard',\n",
      " 'Columbia Center Boulevard',\n",
      " 'Kennedy Road',\n",
      " 'Duportail Street',\n",
      " 'Keene Road',\n",
      " 'Keene Road',\n",
      " 'Queensgate Drive',\n",
      " 'West Bonnie Avenue',\n",
      " 'Columbia Center Boulevard',\n",
      " 'Saint Street',\n",
      " 'West 12th Avenue',\n",
      " 'S OCTAVE ST',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'West Octave Street',\n",
      " 'North 3rd Avenue',\n",
      " 'North 3rd Avenue',\n",
      " 'Keene Road',\n",
      " 'Keene Road',\n",
      " 'Keene Road',\n",
      " 'Keene Road',\n",
      " 'Elementary Street',\n",
      " 'Elementary Street',\n",
      " 'Broadmoor Boulevard',\n",
      " 'Dale Avenue',\n",
      " 'Dale Avenue',\n",
      " 'Queensgate Drive',\n",
      " 'West 12th Avenue',\n",
      " 'West 12th Avenue',\n",
      " 'South Union Street',\n",
      " 'West 12th Avenue',\n",
      " 'West 12th Avenue',\n",
      " 'West 12th Avenue',\n",
      " 'West 12th Avenue',\n",
      " 'Duportail Street',\n",
      " 'Aaron Drive',\n",
      " 'Wellsian Way',\n",
      " 'Columbia Park Trail',\n",
      " 'West 12th Avenue',\n",
      " 'West 12th Avenue',\n",
      " 'West 12th Avenue',\n",
      " 'Apollo Boulevard',\n",
      " 'Columbia Point Drive',\n",
      " 'Columbia Point Drive',\n",
      " 'Williams Boulevard',\n",
      " 'Williams Boulevard',\n",
      " 'Swift Boulevard',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'Jadwin Avenue',\n",
      " 'George Washington Way',\n",
      " 'Goethals Drive',\n",
      " 'McMurray Street',\n",
      " 'Columbia Center Boulevard',\n",
      " 'West Canal Drive',\n",
      " 'North Columbia Center Boulevard',\n",
      " 'West Canal Drive',\n",
      " 'West Canal Drive',\n",
      " 'North Columbia Center Boulevard',\n",
      " 'North Columbia Center Boulevard',\n",
      " 'South Cedar Street',\n",
      " 'South Washington Street',\n",
      " 'South Washington Street',\n",
      " 'South Washington Street',\n",
      " 'South Washington Street',\n",
      " 'South Washington Street',\n",
      " 'South Washington Street',\n",
      " 'Thayer Drive',\n",
      " 'North Edison Street',\n",
      " 'West Okanogan Avenue',\n",
      " 'George Washington Way',\n",
      " 'Bedford Street',\n",
      " 'Bedford Street',\n",
      " 'Road 72',\n",
      " 'Swift Boulevard',\n",
      " 'George Washington Way',\n",
      " 'Bradley Boulevard',\n",
      " 'George Washington Way',\n",
      " 'George Washington Way',\n",
      " 'George Washington Way',\n",
      " 'West Metaline Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'West 20th Avenue',\n",
      " 'North Columbia Center Boulevard',\n",
      " 'Kingsgate Way',\n",
      " 'North Steptoe Street',\n",
      " 'West 27th Avenue',\n",
      " 'West Van Giesen Street',\n",
      " '9th Street',\n",
      " 'West 7th Avenue',\n",
      " 'West 7th Avenue',\n",
      " 'West 7th Avenue',\n",
      " 'West Clearwater Avenue',\n",
      " 'West Kennewick Avenue',\n",
      " 'North Ely Street',\n",
      " 'West Canal Drive',\n",
      " 'South Quillan Street',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'West 6th Avenue',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'West 7th Avenue',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'South Perry Court',\n",
      " 'West 2nd Avenue',\n",
      " 'West 2nd Avenue',\n",
      " 'West Kennewick Avenue',\n",
      " 'North Ely Street',\n",
      " 'North Ely Street',\n",
      " 'West Vista Way',\n",
      " 'West Vista Way',\n",
      " 'West Vista Way',\n",
      " 'West Vista Way',\n",
      " 'West Kennewick Avenue',\n",
      " 'West Kennewick Avenue',\n",
      " 'West Kennewick Avenue',\n",
      " 'West Albany Avenue',\n",
      " 'West Kennewick Avenue',\n",
      " 'North Ely Street',\n",
      " 'North Huntington Street',\n",
      " 'West 27th Avenue',\n",
      " 'Ridgeline Drive',\n",
      " 'Highway 240',\n",
      " 'Bombing Range Road',\n",
      " 'Duportail Street',\n",
      " 'Lacy Road',\n",
      " 'Cougar Road',\n",
      " 'Queensgate Drive',\n",
      " 'Stevens Drive',\n",
      " 'Jadwin Avenue',\n",
      " 'Pike Avenue',\n",
      " 'Saint Street',\n",
      " 'South Tweedt Street']\n"
     ]
    }
   ],
   "source": [
    "def street_names(filename):\n",
    "        key='addr:street'\n",
    "        values=[]\n",
    "        EL=get_element(filename, tags=('node', 'way', 'relation'))\n",
    "        for element in EL:\n",
    "            for tag in element.iter('tag'):\n",
    "                if tag.attrib['k']==key:\n",
    "                    values.append(tag.attrib['v'])\n",
    "            element.clear()\n",
    "        print (key)\n",
    "        pprint.pprint(values)\n",
    "street_names(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The main issue here is that the street name endings are not uniform. For example, some streets end in 'Drive' while others end in 'Dr', or 'Avenue' and 'Ave'. We want all the street name endings to be uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Post Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:postcode\n",
      "['99337',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99337',\n",
      " '99301',\n",
      " '99352',\n",
      " '99301',\n",
      " '99301',\n",
      " '99336',\n",
      " '99354',\n",
      " '99338-7319',\n",
      " '99338-7319',\n",
      " '99338-7319',\n",
      " '99338-7319',\n",
      " '99338-7319',\n",
      " '99338-7319',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99337',\n",
      " '99323',\n",
      " '99336',\n",
      " '99336',\n",
      " '99353',\n",
      " '98352',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99362',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99352',\n",
      " '99301',\n",
      " '9936',\n",
      " '83853',\n",
      " '99336',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99301',\n",
      " '99301',\n",
      " '99336',\n",
      " '99354',\n",
      " '99354',\n",
      " '99337',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99301',\n",
      " '99320',\n",
      " '99353',\n",
      " '99352',\n",
      " '99336',\n",
      " '99337',\n",
      " '99352',\n",
      " '99337',\n",
      " '99337',\n",
      " '99338',\n",
      " '99337',\n",
      " '99336',\n",
      " '99353',\n",
      " '99337',\n",
      " '99337',\n",
      " '99353',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99352',\n",
      " '99337',\n",
      " '99320',\n",
      " '99338',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99354',\n",
      " '99337',\n",
      " '99337',\n",
      " '99352',\n",
      " '99337',\n",
      " '99336',\n",
      " '99353',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99353',\n",
      " '99336',\n",
      " '99337',\n",
      " '99354',\n",
      " '99337',\n",
      " '99336',\n",
      " '99353',\n",
      " '99337',\n",
      " '99337',\n",
      " '99336',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99338',\n",
      " '99337',\n",
      " '99336',\n",
      " '99336',\n",
      " '99320',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99353',\n",
      " '99336',\n",
      " '99336',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99354',\n",
      " '99338',\n",
      " '99338',\n",
      " '99352',\n",
      " '99336',\n",
      " '99337',\n",
      " '99336',\n",
      " '99336',\n",
      " '99352',\n",
      " '99336',\n",
      " '99337',\n",
      " '99336-1117',\n",
      " '99354-2303',\n",
      " '99352',\n",
      " '99338',\n",
      " '99337',\n",
      " '99336',\n",
      " '99352',\n",
      " '99336',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99353',\n",
      " '99336',\n",
      " '99336',\n",
      " '99352',\n",
      " '99352',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99337',\n",
      " '99336',\n",
      " '99337',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99352',\n",
      " '99336',\n",
      " '99336',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99323',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99354',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99352',\n",
      " '99301',\n",
      " '99301',\n",
      " '99354',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99336',\n",
      " '99301',\n",
      " '99337',\n",
      " '99352',\n",
      " '99352',\n",
      " '99336',\n",
      " '99352',\n",
      " '99354',\n",
      " '99336',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99338',\n",
      " '99352',\n",
      " '99354',\n",
      " '99336',\n",
      " '99301',\n",
      " '99352',\n",
      " '99337',\n",
      " '99337',\n",
      " '99301',\n",
      " '99353',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99336',\n",
      " '99336',\n",
      " '99352',\n",
      " '99352',\n",
      " '99353',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99352',\n",
      " '99352',\n",
      " '99353',\n",
      " '99353',\n",
      " '99353',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99336',\n",
      " '99354',\n",
      " '99354',\n",
      " '99301',\n",
      " '99301',\n",
      " '99354',\n",
      " '99336',\n",
      " '99353',\n",
      " '99320',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99336',\n",
      " '99338',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99336',\n",
      " '99336',\n",
      " '99352',\n",
      " '99301',\n",
      " '99354',\n",
      " '99352',\n",
      " '99354',\n",
      " '99337',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99338',\n",
      " '99338',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99362',\n",
      " '99338',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99352',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99336',\n",
      " '99336',\n",
      " '99352',\n",
      " '99338',\n",
      " '99352',\n",
      " '99338',\n",
      " '99338',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99337',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99337',\n",
      " '99336',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99336',\n",
      " '99301',\n",
      " '99301',\n",
      " '99353',\n",
      " '99352',\n",
      " '99320',\n",
      " '99336',\n",
      " '99301',\n",
      " '99301',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99353',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99336',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99338',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99336',\n",
      " '99336',\n",
      " '99301',\n",
      " '99320',\n",
      " '99352',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99338',\n",
      " '99338',\n",
      " '99338',\n",
      " '99354',\n",
      " '99352',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99352',\n",
      " '99354',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99337',\n",
      " '99352',\n",
      " '99336',\n",
      " '99336',\n",
      " '99354',\n",
      " '99301',\n",
      " '99301',\n",
      " '99301',\n",
      " '99352',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99354',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99352',\n",
      " '99338',\n",
      " '99353',\n",
      " '99352',\n",
      " '99352',\n",
      " '99320',\n",
      " '99352',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99337',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99336',\n",
      " '99338',\n",
      " '99338',\n",
      " '99354',\n",
      " '99336',\n",
      " '99353',\n",
      " '99352',\n",
      " '99352',\n",
      " '99337',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99354',\n",
      " '99336']\n"
     ]
    }
   ],
   "source": [
    "def post_codes(filename):\n",
    "        key='addr:postcode'\n",
    "        values=[]\n",
    "        EL=get_element(filename, tags=('node', 'way', 'relation'))\n",
    "        for element in EL:\n",
    "            for tag in element.iter('tag'):\n",
    "                if tag.attrib['k']==key:\n",
    "                    values.append(tag.attrib['v'])\n",
    "            element.clear()\n",
    "        print (key)\n",
    "        pprint.pprint(values)\n",
    "post_codes(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The postcodes are actually relatively clean. The only issue is that the majority of the post codes are 5 digits, like '11111' where as a few of them are 9 digits, like '11111-1111'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing Street Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Setting values we expect and mappings to them from common endings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# The values we expect to see. This is the end result of all street name endings we want\n",
    "expected = [\"Street\", \"Avenue\",\"Loop\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\",\"Freeway\",\"Circle\",\"Strand\",\"Sterling\",\"Way\",\"Highway\",\n",
    "            \"Terrace\",\"South\",\"East\",\"West\",\"North\",\"Landing\"]\n",
    "\n",
    "# Mapping shortened version of common street name endings to the ending we want\n",
    "mapping = {\n",
    "            \" St \": \" Street \",\n",
    "            \" St\": \" Street \",\n",
    "            \" St.\": \" Street \",\n",
    "            \" ST\": \" Street \",\n",
    "            \" Rd.\": \" Road \",\n",
    "            \" Rd \": \" Road \",\n",
    "            \" Rd\": \" Road \",\n",
    "            \" Ave \": \" Avenue \", \n",
    "            \" Ave\": \" Avenue \", \n",
    "            \" Ave.\": \" Avenue \",\n",
    "            \" Av \": \" Avenue \", \n",
    "            \" Dr \": \" Drive \",\n",
    "            \" Dr.\": \" Drive\",\n",
    "            \" Dr\": \" Drive\",\n",
    "            \" Pl \": \" Place\",\n",
    "            \" Pl\": \" Place\",\n",
    "            \" Blvd \": \" Boulevard \",\n",
    "            \" Blvd\": \" Boulevard\",\n",
    "            \" Blvd.\": \" Boulevard\",\n",
    "            \" Ct \": \" Court \",\n",
    "            \" Ct\": \" Court \",\n",
    "            \" Ctr\": \" Center\",\n",
    "            \" Pl \": \" Place \",\n",
    "            \" Ln \": \" Lane \",\n",
    "            \" Cir \": \" Circle \",\n",
    "            \" Wy\": \" Way \",\n",
    "            \" S \": \" South \",\n",
    "            \" E \": \" East \",\n",
    "            \" W \": \" West \",\n",
    "            \" N \": \"North\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Adding expected street names to groups and adding unexpected ones to be handled later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling expected and unexpected street names\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sending street names to be audited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting street names and sending them to audit_street_type function\n",
    "def audit(file):\n",
    "    file = open(file, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Updating the ending names of streets to our preferred type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for replace 'old' names with 'new' names\n",
    "def update_street_name(name, mapping):\n",
    "    for key,value in mapping.items():\n",
    "        if key in name:\n",
    "            return name.replace(key,value)\n",
    "    return name \n",
    "\n",
    "def audit_street_name_tag(element): \n",
    "    street_name=element.get('v')\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        better_street_name=update_street_name(street_name,mapping)\n",
    "        return better_street_name\n",
    "    return street_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Starting the street name auditing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('So. Kent St.', '=>', 'So. Kent Street .')\n",
      "('Road 36', '=>', 'Road 36')\n",
      "('South Washington St', '=>', 'South Washington Street ')\n",
      "('Cottonwood Creek Blvd', '=>', 'Cottonwood Creek Boulevard')\n",
      "('S OCTAVE ST', '=>', 'S OCTAVE Street ')\n",
      "('E. SR 397', '=>', 'E. SR 397')\n",
      "('Road 72', '=>', 'Road 72')\n",
      "('North Road 68', '=>', 'North Road 68')\n",
      "('Willamette Ave', '=>', 'Willamette Avenue ')\n",
      "('West Kennewick Ave', '=>', 'West Kennewick Avenue ')\n",
      "('North Road 92', '=>', 'North Road 92')\n",
      "('Indian Ridge Dr', '=>', 'Indian Ridge Drive')\n",
      "('Tamarisk Dr', '=>', 'Tamarisk Drive')\n",
      "('North Road 44', '=>', 'North Road 44')\n",
      "('N Irving Pl', '=>', 'N Irving Place')\n",
      "('Travis Ct', '=>', 'Travis Court ')\n"
     ]
    }
   ],
   "source": [
    "# Variable for new street names to be stored\n",
    "st_types = audit(OSM_FILE)\n",
    "\n",
    "for st_type, ways in st_types.items():\n",
    "    for name in ways:\n",
    "        better_name = update_street_name(name, mapping)\n",
    "        print (name, \"=>\", better_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now all the common street endings have been updated to the full endings we want. However, there are some areas that may seem like a problem here. There are several endings with a number, such as 'Road 36'. This is actually okay and a correct name. There are many roads around this area that are numbered such as these. We will ignore changing the numbers of these roads because they are already correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing Post Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'83853': set(['83853']),\n",
      " '98352': set(['98352']),\n",
      " '99301': set(['99301']),\n",
      " '99320': set(['99320']),\n",
      " '99323': set(['99323']),\n",
      " '99336': set(['99336']),\n",
      " '99336-1117': set(['99336-1117']),\n",
      " '99337': set(['99337']),\n",
      " '99338': set(['99338']),\n",
      " '99338-7319': set(['99338-7319']),\n",
      " '99352': set(['99352']),\n",
      " '99353': set(['99353']),\n",
      " '99354': set(['99354']),\n",
      " '99354-2303': set(['99354-2303']),\n",
      " '9936': set(['9936']),\n",
      " '99362': set(['99362'])}\n",
      "99323\n",
      "99320\n",
      "99337\n",
      "99336\n",
      "99301\n",
      "99336\n",
      "99338\n",
      "98352\n",
      "99338\n",
      "99353\n",
      "99352\n",
      "83853\n",
      "99354\n",
      "99362\n",
      "00000\n",
      "99354\n"
     ]
    }
   ],
   "source": [
    "zip_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "zip_types = defaultdict(set)\n",
    "\n",
    "expected_zip = {}\n",
    "\n",
    "def audit_zip_codes(zip_types, zip_name, regex, expected_zip):\n",
    "    m = regex.search(zip_name)\n",
    "    if m:\n",
    "        zip_type = m.group()\n",
    "        if zip_type not in expected_zip:\n",
    "             zip_types[zip_type].add(zip_name)\n",
    "\n",
    "def is_zip_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "\n",
    "def audit_zip(filename, regex):\n",
    "    for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "        if elem.tag == \"way\" or elem.tag == \"node\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zip_name(tag):\n",
    "                    audit_zip_codes(zip_types, tag.attrib['v'], regex, expected_zip)\n",
    "    pprint.pprint(dict(zip_types)) \n",
    "\n",
    "    \n",
    "audit_zip(OSM_FILE, zip_type_re)\n",
    "\n",
    "\n",
    "for zip_type, ways in zip_types.iteritems(): \n",
    "        for name in ways:\n",
    "            if \"-\" in name:\n",
    "                name = name.split(\"-\")[0].strip()\n",
    "            elif len(str(name))>5:\n",
    "                name=name[0:5]\n",
    "                # This function because one of the postcodes in the dataset has only 4 digits. This is basically setting\n",
    "                # it to 'unknown' as its all zeros\n",
    "            elif len(str(name))<5:\n",
    "                name = '00000'\n",
    "            print name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The way to audit the postcodes is to make them all uniform. Since the vast majority of them are 5 digits, we will be\n",
    "# auditing the longer codes by stripping off the extra digits and he '-'. This will make every post code a uniform 5 digits\n",
    "def update_postcode(name): \n",
    "    if \"-\" in name:\n",
    "        name = name.split(\"-\")[0].strip()\n",
    "    elif len(str(name))>5:\n",
    "        name=name[0:5]\n",
    "    elif len(str(name))<5:\n",
    "        name = '00000'\n",
    "    return name\n",
    "\n",
    "\n",
    "\n",
    "def audit_postcode_tag(element,regex=re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)):\n",
    "    post_code=element.get('v')\n",
    "    m = regex.search(post_code)\n",
    "    if m:\n",
    "        better_postcode=update_postcode(post_code)\n",
    "        return better_postcode\n",
    "    return post_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing to CSV and Importing to a Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining schema for SQL Database\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining CSV files and fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaping elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and shaping elemnents to Python dict\n",
    "\n",
    "\"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \n",
    "    \n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = [] # Handle secondary tags the same way for both node and way elements\n",
    "             \n",
    "\n",
    "   \n",
    "\n",
    "    if element.tag=='node':\n",
    "        for field in node_attr_fields:\n",
    "            node_attribs[field]=element.get(field)\n",
    "                 \n",
    "        if element.find('tag') is None:\n",
    "            pass\n",
    "           \n",
    "        elif element.find('tag') is not None:\n",
    "            tag_attrib={}\n",
    "            node_tag_fields=NODE_TAGS_FIELDS\n",
    "            for tag in element.iter('tag'):\n",
    "                if PROBLEMCHARS.search(tag.attrib['k']):\n",
    "                    pass\n",
    "                elif LOWER_COLON.search(tag.attrib['k']):\n",
    "                    tag_attrib[node_tag_fields[0]]=element.get('id')\n",
    "                    tag_attrib[node_tag_fields[1]]=tag.get('k')[(tag.get('k').find(':')+1):]\n",
    "                    if tag.attrib['k']== \"addr:street\":\n",
    "                        tag_attrib[node_tag_fields[2]]=audit_street_name_tag(tag)\n",
    "                    elif tag.attrib['k']== \"addr:postcode\":\n",
    "                        tag_attrib[node_tag_fields[2]]=audit_postcode_tag(tag)       \n",
    "                    else:\n",
    "                        tag_attrib[node_tag_fields[2]]=tag.get('v')\n",
    "                    tag_attrib[node_tag_fields[3]]=tag.get('k').split(':')[0]\n",
    "                    tags.append(tag_attrib.copy())\n",
    "                \n",
    "                else:\n",
    "                    tag_attrib[node_tag_fields[0]]=element.get('id')\n",
    "                    tag_attrib[node_tag_fields[1]]=tag.get('k')\n",
    "                    if tag.attrib['k']== \"addr:street\":\n",
    "                        tag_attrib[node_tag_fields[2]]=audit_street_name_tag(tag)\n",
    "                    elif tag.attrib['k']== \"addr:postcode\":\n",
    "                        tag_attrib[node_tag_fields[2]]=audit_postcode_tag(tag)    \n",
    "                    else:    \n",
    "                        tag_attrib[node_tag_fields[2]]=tag.get('v')\n",
    "                    tag_attrib[node_tag_fields[3]]=default_tag_type\n",
    "                    tags.append(tag_attrib.copy())\n",
    "             \n",
    "        \n",
    "                \n",
    "    elif element.tag=='way':\n",
    "        for field in way_attr_fields:\n",
    "            way_attribs[field]=element.get(field)\n",
    "    \n",
    "        way_node_attrib={}\n",
    "        way_node_fields=WAY_NODES_FIELDS\n",
    "        for nd in element.findall('nd'):\n",
    "            way_node_attrib[way_node_fields[0]]=element.get('id')\n",
    "            way_node_attrib[way_node_fields[1]]=nd.get('ref')\n",
    "            way_node_attrib[way_node_fields[2]]=element.findall('nd').index(nd)\n",
    "            way_nodes.append(way_node_attrib.copy())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if element.find('tag') is None:\n",
    "            pass\n",
    "           \n",
    "        elif element.find('tag') is not None:\n",
    "            way_tag_attrib={}\n",
    "            way_tag_fields=WAY_TAGS_FIELDS\n",
    "            for tag in element.iter('tag'):\n",
    "                if PROBLEMCHARS.search(tag.attrib['k']):\n",
    "                    pass\n",
    "                elif LOWER_COLON.search(tag.attrib['k']):\n",
    "                    way_tag_attrib[way_tag_fields[0]]=element.get('id')\n",
    "                    way_tag_attrib[way_tag_fields[1]]=tag.get('k')[(tag.get('k').find(':')+1):]\n",
    "                    if tag.attrib['k']== \"addr:street\":\n",
    "                        way_tag_attrib[way_tag_fields[2]]=audit_street_name_tag(tag)\n",
    "                    elif tag.attrib['k']== \"addr:postcode\":\n",
    "                        way_tag_attrib[way_tag_fields[2]]=audit_postcode_tag(tag)    \n",
    "                    else:\n",
    "                        way_tag_attrib[way_tag_fields[2]]=tag.get('v')\n",
    "                    way_tag_attrib[way_tag_fields[3]]=tag.get('k').split(':')[0]\n",
    "                    tags.append(way_tag_attrib.copy())\n",
    "                    \n",
    "                else:\n",
    "                    way_tag_attrib[way_tag_fields[0]]=element.get('id')\n",
    "                    way_tag_attrib[way_tag_fields[1]]=tag.get('k')\n",
    "                    if tag.attrib['k']== \"addr:street\":\n",
    "                        way_tag_attrib[way_tag_fields[2]]=audit_street_name_tag(tag) \n",
    "                    elif tag.attrib['k']== \"addr:postcode\":\n",
    "                        way_tag_attrib[way_tag_fields[2]]=audit_postcode_tag(tag)    \n",
    "                    else:   \n",
    "                        way_tag_attrib[way_tag_fields[2]]=tag.get('v')\n",
    "                    way_tag_attrib[way_tag_fields[3]]=default_tag_type\n",
    "                    tags.append(way_tag_attrib.copy())\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Element\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Element\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict Writer\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the process\n",
    "if __name__ == '__main__':\n",
    "    process_map(OSM_FILE, validate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "mydb = 'tricities.db'\n",
    "conn = sqlite3.connect(mydb)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop table if already exists\n",
    "query=\"DROP TABLE IF EXISTS nodes;\"\n",
    "cur.execute(query);\n",
    "conn.commit()\n",
    "query = \"CREATE TABLE nodes (id INTEGER PRIMARY KEY NOT NULL,lat REAL,lon REAL,user TEXT,uid INTEGER,version INTEGER,changeset INTEGER,timestamp TEXT);\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "# Open CSV file and formatting data\n",
    "with open('nodes.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['lat'].decode(\"utf-8\"),i['lon'].decode(\"utf-8\"),i['user'].decode(\"utf-8\"),i['uid'].decode(\"utf-8\"),i['version'].decode(\"utf-8\"),i['changeset'].decode(\"utf-8\"),i['timestamp'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# Insert Data\n",
    "cur.executemany(\"INSERT INTO nodes (id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?,?,?);\", to_db)\n",
    "conn.commit()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes_Tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop table if already exists\n",
    "query=\"DROP TABLE IF EXISTS nodes_tags;\"\n",
    "cur.execute(query);\n",
    "conn.commit()\n",
    "query = \"CREATE TABLE nodes_tags (id INTEGER,key TEXT,value TEXT,type TEXT,FOREIGN KEY (id) REFERENCES nodes(id));\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "# Open CSV file and formatting data\n",
    "with open('nodes_tags.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"),i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# Insert Data\n",
    "cur.executemany(\"INSERT INTO nodes_tags (id, key, value, type) VALUES (?,?,?,?);\", to_db)\n",
    "conn.commit()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop table if already exists\n",
    "query=\"DROP TABLE IF EXISTS ways;\"\n",
    "cur.execute(query);\n",
    "conn.commit()\n",
    "query = \"CREATE TABLE ways(id INTEGER PRIMARY KEY NOT NULL,user TEXT,uid INTEGER,version TEXT,changeset INTEGER,timestamp TEXT);\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "# Open CSV file and formatting data\n",
    "with open('ways.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['user'].decode(\"utf-8\"),i['uid'].decode(\"utf-8\"),i['version'].decode(\"utf-8\"),i['changeset'].decode(\"utf-8\"),i['timestamp'].decode(\"utf-8\")) for i in dr]\n",
    "    \n",
    "# Insert Data\n",
    "cur.executemany(\"INSERT INTO ways (id, user, uid, version, changeset, timestamp) VALUES (?,?,?,?,?,?);\", to_db)\n",
    "conn.commit()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways_Tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop table if already exists\n",
    "query=\"DROP TABLE IF EXISTS ways_tags;\"\n",
    "cur.execute(query);\n",
    "conn.commit()\n",
    "query = \"CREATE TABLE ways_tags (id INTEGER NOT NULL,key TEXT NOT NULL,value TEXT NOT NULL,type TEXT,FOREIGN KEY (id) REFERENCES ways(id));\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "# Open CSV file and formatting data\n",
    "with open('ways_tags.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['key'].decode(\"utf-8\"),i['value'].decode(\"utf-8\"),i['type'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# Insert Data\n",
    "cur.executemany(\"INSERT INTO ways_tags (id, key, value, type) VALUES (?,?,?,?);\", to_db)\n",
    "conn.commit()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways_Nodes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop table if already exists\n",
    "query=\"DROP TABLE IF EXISTS ways_nodes;\"\n",
    "cur.execute(query);\n",
    "conn.commit()\n",
    "query = \"CREATE TABLE ways_nodes (id INTEGER NOT NULL,node_id INTEGER NOT NULL,position INTEGER NOT NULL,FOREIGN KEY (id) REFERENCES ways(id),FOREIGN KEY (node_id) REFERENCES nodes(id));\"\n",
    "cur.execute(query)\n",
    "conn.commit()\n",
    "\n",
    "# Open CSV file and formatting data\n",
    "with open('ways_nodes.csv','rb') as f: \n",
    "    dr = csv.DictReader(f)\n",
    "    to_db = [(i['id'].decode(\"utf-8\"),i['node_id'].decode(\"utf-8\"),i['position'].decode(\"utf-8\")) for i in dr]\n",
    "\n",
    "# Insert Data\n",
    "cur.executemany(\"INSERT INTO ways_nodes (id, node_id, position) VALUES (?,?,?);\", to_db)\n",
    "conn.commit()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Size (In bytes) of 'tri_cities.db':\", 42356736L)\n",
      "(\"Size (In bytes) of 'map.osm':\", 82031159L)\n",
      "(\"Size (In bytes) of 'nodes.csv':\", 31701618L)\n",
      "(\"Size (In bytes) of 'ways.csv':\", 2396620L)\n",
      "(\"Size (In bytes) of 'nodes_tags.csv':\", 1158419L)\n",
      "(\"Size (In bytes) of 'ways_tags.csv':\", 4416724L)\n",
      "(\"Size (In bytes) of 'ways_nodes.csv':\", 10807215L)\n"
     ]
    }
   ],
   "source": [
    "#links to the csv files\n",
    "nodes_csv = 'nodes.csv'\n",
    "ways_csv = 'ways.csv'\n",
    "nodestags_csv = 'nodes_tags.csv'\n",
    "waystags_csv = 'ways_tags.csv'\n",
    "waysnodes_csv = 'ways_nodes.csv'\n",
    "\n",
    "# Get the size (in bytes) of specified path  \n",
    "size_tricitiesdb = os.path.getsize('tricities.db')\n",
    "size_osm_xml = os.path.getsize('map.osm')\n",
    "size_nodes = os.path.getsize(nodes_csv) \n",
    "size_ways = os.path.getsize(ways_csv) \n",
    "size_nodestags = os.path.getsize(nodestags_csv) \n",
    "size_waystags = os.path.getsize(waystags_csv) \n",
    "size_waysnodes = os.path.getsize(waysnodes_csv) \n",
    "  \n",
    "# Print the size (in bytes) of specified path  \n",
    "print(\"Size (In bytes) of '%s':\" %'tri_cities.db', size_tricitiesdb)\n",
    "print(\"Size (In bytes) of '%s':\" %'map.osm', size_osm_xml)\n",
    "print(\"Size (In bytes) of '%s':\" %nodes_csv, size_nodes)\n",
    "print(\"Size (In bytes) of '%s':\" %ways_csv, size_ways)\n",
    "print(\"Size (In bytes) of '%s':\" %nodestags_csv, size_nodestags)\n",
    "print(\"Size (In bytes) of '%s':\" %waystags_csv, size_waystags)\n",
    "print(\"Size (In bytes) of '%s':\" %waysnodes_csv, size_waysnodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(368263,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT count(DISTINCT(id)) FROM nodes;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(38417,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT count(DISTINCT(id)) FROM ways;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Contributing Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Jessica12345', 102374),\n",
      " (u'Howpper', 68010),\n",
      " (u'DJ Cane', 38615),\n",
      " (u'OrcaDan', 23035),\n",
      " (u'woodpeck_fixbot', 15212),\n",
      " (u'Sundance', 14827),\n",
      " (u'miroslavuzice87', 11778),\n",
      " (u'bab72', 9732),\n",
      " (u'Natfoot', 9487),\n",
      " (u'Brad Meteor', 8091),\n",
      " (u'shutle64', 6252),\n",
      " (u'zephyr', 4888),\n",
      " (u'Heptazane', 4599),\n",
      " (u'caseyb', 4553),\n",
      " (u'Glassman', 4247),\n",
      " (u'cowdog', 4133),\n",
      " (u'SuperFlomm', 3086),\n",
      " (u'Something B', 2881),\n",
      " (u'Dilys', 2311),\n",
      " (u'Aaron Lidman', 2199),\n",
      " (u'TheDutchMan13', 2105),\n",
      " (u'Timothy Whidden', 2103),\n",
      " (u'eyewitness', 2097),\n",
      " (u'leuty', 2034),\n",
      " (u'PHerison', 1980)]\n"
     ]
    }
   ],
   "source": [
    "query= 'SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 25;'\n",
    "cur.execute(query)\n",
    "rows = cur.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type and Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'regular', 28310),\n",
      " (u'addr', 854),\n",
      " (u'gnis', 417),\n",
      " (u'generator', 341),\n",
      " (u'brand', 333),\n",
      " (u'railway', 120),\n",
      " (u'tower', 40),\n",
      " (u'seamark', 39),\n",
      " (u'traffic_signals', 23),\n",
      " (u'name', 22),\n",
      " (u'fire_hydrant', 21),\n",
      " (u'toilets', 19),\n",
      " (u'opening_hours', 15),\n",
      " (u'healthcare', 13),\n",
      " (u'socket', 11),\n",
      " (u'flag', 9),\n",
      " (u'monitoring', 6),\n",
      " (u'authentication', 6),\n",
      " (u'was', 4),\n",
      " (u'census', 4),\n",
      " (u'handwashing', 3),\n",
      " (u'disused', 3),\n",
      " (u'turn', 2),\n",
      " (u'ref', 2),\n",
      " (u'parking', 2),\n",
      " (u'operator', 2),\n",
      " (u'is_in', 2),\n",
      " (u'internet_access', 2),\n",
      " (u'crossing', 2),\n",
      " (u'contact', 2),\n",
      " (u'charging_station', 2),\n",
      " (u'wetap', 1),\n",
      " (u'survey', 1),\n",
      " (u'stop', 1),\n",
      " (u'roof', 1),\n",
      " (u'payment', 1),\n",
      " (u'fuel', 1),\n",
      " (u'diet', 1),\n",
      " (u'building', 1),\n",
      " (u'aerodrome', 1),\n",
      " (u'abandoned', 1)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT type , count(*) as num  FROM nodes_tags group by type order by num desc;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type and Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'regular', 79771),\n",
      " (u'tiger', 37677),\n",
      " (u'addr', 2502),\n",
      " (u'source', 437),\n",
      " (u'building', 405),\n",
      " (u'brand', 303),\n",
      " (u'roof', 296),\n",
      " (u'lanes', 210),\n",
      " (u'gnis', 206),\n",
      " (u'turn', 180),\n",
      " (u'hgv', 117),\n",
      " (u'destination', 95),\n",
      " (u'name', 78),\n",
      " (u'maxspeed', 63),\n",
      " (u'parking', 43),\n",
      " (u'cycleway', 41),\n",
      " (u'payment', 39),\n",
      " (u'opening_hours', 21),\n",
      " (u'crossing', 15),\n",
      " (u'abandoned', 14),\n",
      " (u'disused', 13),\n",
      " (u'is_in', 11),\n",
      " (u'operator', 10),\n",
      " (u'internet_access', 8),\n",
      " (u'fuel', 8),\n",
      " (u'healthcare', 7),\n",
      " (u'ref', 6),\n",
      " (u'historic', 5),\n",
      " (u'bridge', 5),\n",
      " (u'surface', 4),\n",
      " (u'seamark', 3),\n",
      " (u'razed', 2),\n",
      " (u'note', 2),\n",
      " (u'heritage', 2),\n",
      " (u'footway', 2),\n",
      " (u'diet', 2),\n",
      " (u'contact', 2),\n",
      " (u'wikipedia', 1),\n",
      " (u'toilets', 1),\n",
      " (u'theatre', 1),\n",
      " (u'socket', 1),\n",
      " (u'service_times', 1),\n",
      " (u'planned', 1),\n",
      " (u'observatory', 1),\n",
      " (u'capacity', 1)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT type , count(*) as num  FROM ways_tags group by type order by num desc;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biggest Religions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'christian', 37), (u'muslim', 1), (u'hindu', 1)]\n"
     ]
    }
   ],
   "source": [
    "query=\"select value, count(*) as num from (select key,value from nodes_tags UNION ALL select key,value from ways_tags) as e  where key='religion' group by value order by num desc limit 10;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Quisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'burger', 36),\n",
      " (u'coffee_shop', 23),\n",
      " (u'pizza', 19),\n",
      " (u'mexican', 18),\n",
      " (u'sandwich', 13),\n",
      " (u'american', 9),\n",
      " (u'tex-mex', 7),\n",
      " (u'chinese', 6),\n",
      " (u'seafood', 4),\n",
      " (u'ice_cream;burger', 4),\n",
      " (u'chicken', 4),\n",
      " (u'asian', 4),\n",
      " (u'thai', 3),\n",
      " (u'italian', 3),\n",
      " (u'wings', 2),\n",
      " (u'juice', 2),\n",
      " (u'breakfast;pancake', 2),\n",
      " (u'sushi', 1),\n",
      " (u'steak_house;sushi', 1),\n",
      " (u'steak_house', 1),\n",
      " (u'pretzel', 1),\n",
      " (u'mongolian', 1),\n",
      " (u'mediterranean', 1),\n",
      " (u'korean', 1),\n",
      " (u'kebab', 1)]\n"
     ]
    }
   ],
   "source": [
    "query=\"select value,count(*) as num from (select key,value from nodes_tags UNION ALL select key,value from ways_tags) as e where e.key like '%cuisine%' group by value order by num desc limit 25;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'bench', 151),\n",
      " (u'restaurant', 52),\n",
      " (u'toilets', 51),\n",
      " (u'fast_food', 46),\n",
      " (u'parking', 30),\n",
      " (u'waste_basket', 29),\n",
      " (u'shelter', 28),\n",
      " (u'school', 22),\n",
      " (u'vending_machine', 21),\n",
      " (u'fuel', 20),\n",
      " (u'bicycle_parking', 16),\n",
      " (u'cafe', 15),\n",
      " (u'place_of_worship', 12),\n",
      " (u'drinking_water', 11),\n",
      " (u'bank', 11),\n",
      " (u'dentist', 10),\n",
      " (u'atm', 9),\n",
      " (u'clinic', 8),\n",
      " (u'post_box', 6),\n",
      " (u'pharmacy', 6),\n",
      " (u'loading_dock', 6),\n",
      " (u'ice_cream', 4),\n",
      " (u'fountain', 4),\n",
      " (u'post_office', 3),\n",
      " (u'letter_box', 3)]\n"
     ]
    }
   ],
   "source": [
    "query=\"select value, count(*) as num from nodes_tags where key='amenity' group by value order by num desc limit 25;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(447,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(DISTINCT(e.uid))FROM (SELECT uid FROM Nodes UNION ALL SELECT uid FROM Ways) as e;\"\n",
    "cur.execute(query)\n",
    "rows=cur.fetchall()\n",
    "\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Additional improvement that could be made to the dataset is just overall human error correction. Any dataset this large that is entirely comprised of human input will have errors and doing cleaning and analysis like this on all types of different data points would make the data much more uniform across the dataset. This could be improved by having a uniform data entering scheme that all users of OpenStreetMaps have to follow to submit data. This could help keep the data between different users much more uniform in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This dataset is very large and comprised entirely of information provided by many different users. Different users entering different data at different times leads to some messy data. Going through and cleaning the data like this helps to make the data overall much more uniform and readable. Having a standardized data entering scheme would keep the data much more uniform from the start, however, for a completely open-source website that anyone can enter on, the data was overall very clean. It certainly could have been much worse. The way users enter data is probably about as good as it can be, and for users who prefer more clean data, and analysis such as this could be carried out to standardize all the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
